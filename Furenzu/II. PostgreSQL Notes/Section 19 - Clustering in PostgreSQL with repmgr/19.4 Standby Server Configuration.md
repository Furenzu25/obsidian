# ğŸ–¥ï¸ PostgreSQL Cluster: Setting Up Standby Servers

## ğŸ‘‹ Introduction

Hey guys! In this session, weâ€™re setting up **Standby Servers** as part of our **PostgreSQL high availability cluster** using **repmgr**. Weâ€™ll work with:

- `PG1` â¡ï¸ Primary server
    
- `PG2` â¡ï¸ Standby 1
    
- `PG3` â¡ï¸ Standby 2
    

This setup can scale from 2 to many more nodes. Letâ€™s go! ğŸš€

---

## ğŸ”§ Configuring Standby Servers (PG2 & PG3)

### ğŸ› ï¸ Edit `repmgr.conf` on PG2

- `node_id=2`
    
- `node_name='node2'`
    
- `conninfo='host=PG2 user=repmgr dbname=repmgr'`
    
- `data_directory='/var/lib/postgresql/15/main'`
    
- `priority=60`
    
- `monitoring_history=yes`
    
- `failover=automatic`
    
- `promote_command='...'`
    
- `reconnect_attempts=4`
    
- `reconnect_interval=8`
    
- `monitor_interval_secs=2`
    
- Add daemon commands for managing PostgreSQL and repmgr.
    

ğŸ” PG2 will monitor the cluster and reconnect in case of failure. It will also participate in failover elections.

### ğŸ› ï¸ Edit `repmgr.conf` on PG3

- `node_id=3`
    
- `node_name='node3'`
    
- `priority=40` (Lower than PG2 for failover order)
    
- Other settings same as PG2
    

---

## ğŸ—‘ï¸ Delete and Recreate Data Directory

Replication is **not** a backup. We must remove any existing data on PG2 & PG3 before cloning from the primary:

bash

CopyEdit

`sudo rm -rf /var/lib/postgresql/15/main/*`

ğŸ§ª Run a **Dry Run Clone Check** to verify prerequisites:

bash

CopyEdit

`repmgr -h PG1 -U repmgr -d repmgr -f /etc/repmgr.conf standby clone --dry-run`

âœ… If successful, proceed with:

bash

CopyEdit

`repmgr -h PG1 -U repmgr -d repmgr -f /etc/repmgr.conf standby clone`

Repeat the process separately for PG2 and PG3. Do **not** clone both at the same time to avoid conflicts/errors.

---

## ğŸ“ Registering the Standby Nodes

### âœ… PG2

bash

CopyEdit

`sudo -u postgres repmgr -f /etc/repmgr.conf standby register --upstream-node-id=1`

Check cluster status:

bash

CopyEdit

`repmgr cluster show`

ğŸ“¦ PG2 should now show as Standby with priority 60.

### âœ… PG3

Repeat the same with:

bash

CopyEdit

`sudo -u postgres repmgr -f /etc/repmgr.conf standby register --upstream-node-id=1`

It should appear as Node 3 with priority 40.

---

## ğŸ” Replication Test (Live Demo!)

Letâ€™s test replication is working:

1. Connect to **PG1**:
    
    bash
    
    CopyEdit
    
    `psql -U postgres CREATE DATABASE test_one;`
    
2. Now log into **PG2** and **PG3**:
    
    bash
    
    CopyEdit
    
    `\l`
    
    âœ… `test_one` database should be visible in all nodes!
    
3. You can also run:
    
    sql
    
    CopyEdit
    
    `SELECT * FROM pg_stat_replication;`
    
    ğŸ§  This shows the replication status, lag, and connection types (streaming/asynchronous).
    

---

## ğŸ§ª Insert & Schema Sync Test

On **PG1**, run:

sql

CopyEdit

`CREATE SCHEMA test_schema; CREATE TABLE test_schema.employees (   id SERIAL PRIMARY KEY,   name TEXT,   salary NUMERIC ); INSERT INTO test_schema.employees (name, salary) VALUES ('Alice', 50000);`

Then verify on **PG2** and **PG3**:

sql

CopyEdit

`SELECT * FROM test_schema.employees;`

âœ”ï¸ You should see the same data. Replication is confirmed!

---

## ğŸ” Final Notes

- âœ… All servers are now part of the cluster.
    
- ğŸ” Automatic failover is enabled.
    
- ğŸ“¡ Real-time replication is working.
    
- ğŸ§© Each node monitors the others.
    

Next up: **Witness server configuration** to help elect the new Primary in case of failover! ğŸ‘€

---

## âœ… Key Commands Cheat Sheet

|Task|Command|
|---|---|
|Dry Run Clone Check|`repmgr standby clone --dry-run`|
|Clone from Primary|`repmgr standby clone`|
|Register Standby|`repmgr standby register --upstream-node-id=1`|
|Show Cluster Status|`repmgr cluster show`|
|Check Replication Stats|`SELECT * FROM pg_stat_replication;`|

---

ğŸ“š **Summary**: We successfully configured two Standby servers with priority-based failover, monitored replication health, and confirmed synchronization. Our PostgreSQL cluster is now up and running! ğŸ™Œ

ğŸ‘‰ Up next: Setting up the Witness node.