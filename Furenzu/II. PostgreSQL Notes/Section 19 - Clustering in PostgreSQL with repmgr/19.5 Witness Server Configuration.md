## 🛰️ PostgreSQL Cluster: Witness Server Configuration – Study Notes

### 🧠 **Objective**

The **Witness Server** plays a critical role in a PostgreSQL replication cluster. It **monitors the primary and standby nodes** and is responsible for **triggering failover** when the primary goes down.

---

### 🛠️ **What is the Witness Server?**

- Acts as a **monitor** for the entire cluster.
    
- **Does not store data** or participate in replication.
    
- Used to **promote** a standby server to **primary** in the event of a failure.
    
- It’s like an **observer node** that ensures high availability of the cluster.
    

---

### ⚙️ **Configuration Steps**

#### 1. 🧑‍💻 **Access the server as root**

- Configure the `repmgr.conf` file.
    
- No need to configure a data directory (unlike standby or primary).
    
- Only `repmgr` needs to be set up.
    

#### 2. 📝 **Edit `repmgr.conf`**

- Use settings **similar to standby nodes**, but:
    
    - **No priority** setting (only standby servers have priority).
        
- Save and exit.
    

#### 3. 🔄 **Restart Postgres**

- Apply the new configurations.
    

#### 4. 🔗 **Ensure Communication**

- Verify that PG1 (primary) communicates with Witness (this was pre-tested).
    

---

### 🧾 **Registering Witness in the Cluster**

- Login as **Postgres** user.
    
- Use the following command:
	    
	    arduino
	    
    `repmgr witness register -f /etc/repmgr.conf`
    
- If an error occurs, reconnect and retry.
    
- Witness will now appear in `repmgr cluster show` as **Node 4** (or next available ID).
    
- Note: It **doesn't act as a database server**—just as a monitoring node.
    

---

### 🧪 **Failover Simulation Test**

#### 🛑 **Stop Primary Server (Node 1)**

- Stop or shut down Node 1 (primary).
    
- The Witness detects the failure:
    
    - After a few retries (based on timeout settings), it promotes Node 2 (standby) to become the **new primary**.
        
- This automatic promotion is based on **priority settings** (e.g., Node 2 had priority 60).
    

#### ✅ **Verify Failover**

- Run:
		
		pgsql
		
    `repmgr cluster show`
    
- You’ll see:
    
    - Node 1 → offline
        
    - Node 2 → new primary
        
    - Node 3 → remains standby
        

---

### 🔁 **Restoring Node 1 (Previous Primary)**

Once Node 1 comes back online, you must avoid **dual primaries**. You have two options:

#### Option 1: Clean Restore

1. Stop PostgreSQL on Node 2 (current primary).
    
2. **Rebuild Node 2** from Node 1.
    
3. Register Node 2 again as **standby**.
    

#### Option 2: Keep Node 2 as Primary

- Leave Node 2 as the main primary going forward.
    
- Update roles and settings accordingly.
    

💡 **Pro Tip**: Perform these steps during maintenance to avoid confusion and ensure service continuity.

---

### 🧪 **Replication Validation**

- Connect via `psql` on Node 2 (now primary).
    
- Run a `SELECT` query to confirm data is intact.
    
- This confirms **replication is working perfectly** despite failover.
    

---

### 📌 Summary

|Component|Role|Notes|
|---|---|---|
|**Node 1**|Original Primary|Failed, then restored|
|**Node 2**|Standby → New Primary|Promoted automatically|
|**Node 3**|Standby|Continues as standby|
|**Witness (Node 4)**|Monitor|Orchestrates failover decision|

---

### ✅ Key Takeaways

- The **Witness** server is crucial for **automatic failover**.
    
- It doesn’t store data or participate in replication.
    
- It watches over the cluster and **makes decisions** when failures occur.
    
- Failover is based on **priority values** set in the config files.
    
- After recovery, proper **restoration or reassignment** of roles is critical to avoid inconsistencies.
    

---

### 📣 Final Words

That's it for the Witness server configuration! 👏  
In the next class, you'll learn how to **manually switch the primary** server — a quick and simple trick, but very useful!  
If you have questions, don't hesitate to ask in the course platform.

🧑‍🏫 Until next time!