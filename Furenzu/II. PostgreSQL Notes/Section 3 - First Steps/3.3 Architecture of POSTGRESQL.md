# **PostgreSQL Architecture â€“ Study Notes**

## ðŸ§  Overview

In this lesson, we reviewed how a **single-instance PostgreSQL architecture** works â€” no clustering or load balancing, just the basics. The goal is to understand the **internal processes and memory management** involved when clients interact with a PostgreSQL database.

---

## âš™ï¸ Core Process â€“ `postmaster`

- The `postmaster` is the **main PostgreSQL process**.
    
- It:
    
    - Listens on the default port `5432`.
        
    - Accepts new client connections.
        
    - Forks a **new backend process** for each accepted connection.
        

---

## ðŸ‘¥ Client Connections and Backend Processes

- For each connection (Client1, Client2, etc.), a **dedicated backend process** is created.
    
- These processes handle:
    
    - Reading the TCP stream.
        
    - Parsing and planning the SQL query.
        
    - Executing the query.
        
    - Returning the result.
        

### ðŸ” Memory Usage

- Each backend process uses **its own isolated virtual memory**.
    
- The `work_mem` parameter controls how much memory is used for operations like sorting and hashing.
    

---

## ðŸ“ˆ Scalability Considerations

- More connections = More backend processes = More CPU & memory usage.
    
- PostgreSQL is designed with a **default max connection limit of 100**, which is considered **optimal and safe**.
    

> Example: A web app may serve 1 million users with just a **single database connection**, due to backend pooling mechanisms.

---

## ðŸ§µ Background Workers and Parallel Queries

### ðŸ› ï¸ Worker Processes

- Web servers often create multiple **worker threads per CPU core** to handle connections efficiently.
    

### âš¡ Parallel Queries

- PostgreSQL supports parallel queries â€” one query split across multiple cores.
    
- Controlled by `max_parallel_workers_per_gather`.
    
- Use with caution: it can **increase CPU usage**.
    

> A simple query wonâ€™t trigger parallelism unless itâ€™s complex enough to justify it.

---

## ðŸ”„ Auxiliary Processes in PostgreSQL

### Key Processes:

|**Abbr.**|**Name**|**Role**|
|---|---|---|
|**BGW**|Background Writer|Flushes **dirty pages** (modified memory not yet saved to disk).|
|**CKPT**|Checkpointer|Forces dirty pages to disk and ensures **data durability and recovery**.|
|**WAL**|Write-Ahead Logging|Logs every transaction for **crash recovery and backups**.|
|**LOG**|Logger|Records warnings, errors, and SQL commands.|
|**AVL**|Autovacuum Launcher|Cleans up dead rows for performance and space efficiency.|
|**WWR**|WAL Writer|Writes WAL logs to disk during transactions.|
|**WALR**|WAL Receiver|Receives WALs from primary server (used in replication).|

---

## ðŸ“ WAL Files and Backups

- **WAL (Write-Ahead Logs)** are created for **every transaction** (INSERT, DELETE, UPDATE).
    
- These logs are critical for:
    
    - Crash recovery
        
    - Precise backups
        
- Older WAL files are automatically **archived and deleted** once no longer needed.
    

> Best practice: send WALs to a **remote server** for backup safety.

---

## ðŸ§¹ Maintenance and Clean-Up

- **Autovacuum** and **checkpoint** processes manage memory and disk usage.
    
- These systems ensure:
    
    - Efficient use of RAM.
        
    - Transactions are properly written to disk.
        
    - Old data/files are removed or archived.
        

---

## ðŸ“Œ Key Takeaways

- PostgreSQL spawns a **new backend process for each client connection**.
    
- Each backend uses its **own memory** and is **isolated** from others.
    
- Background and auxiliary processes keep the system running smoothly.
    
- **Parallelism and memory management** must be handled carefully for performance.
    
- The **default max_connections = 100** is a smart limit to avoid overloading resources.